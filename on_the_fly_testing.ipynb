{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycromanager\n",
    "from pycromanager import Core\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "core = Core()\n",
    "#from mmpycorex import download_and_install_mm\n",
    "#download_and_install_mm(\"C:\\\\Program Files\\\\Micro-Manager-pycro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\\\n"
     ]
    }
   ],
   "source": [
    "print(\"test\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    tagged_image = core.get_tagged_image()\n",
    "    # get the pixels in numpy array and reshape it according to its height and width\n",
    "    image_array = np.reshape(\n",
    "        tagged_image.pix,\n",
    "        newshape=[-1, tagged_image.tags[\"Height\"], tagged_image.tags[\"Width\"]],\n",
    "    )\n",
    "    # for display, we can scale the image into the range of 0~255\n",
    "    image_array = (image_array / image_array.max() * 255).astype(\"uint8\")\n",
    "    # return the first channel if multiple exists\n",
    "    return image_array[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch_utils.transform import NormalizeIntensityTrace \n",
    "from torchvision import transforms\n",
    "from torch_utils.transform import BackgroundRemovalNormalize, SkipFrames\n",
    "\n",
    "def inference(model: torch.nn.Module, input: torch.Tensor, apply_transforms: bool = False) -> torch.Tensor:\n",
    "    if apply_transforms:\n",
    "        f = transforms.Compose(\n",
    "            [NormalizeIntensityTrace(),\n",
    "            SkipFrames(skip=3),]\n",
    "        )\n",
    "        input = f(input)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ## Video data has shape (frames, width, height)\n",
    "        ## Expected input: (batches, frames, channels, width, height)\n",
    "        input = input.unsqueeze(0).unsqueeze(2)\n",
    "\n",
    "        output = model.forward(input, inference=True)\n",
    "\n",
    "        return output.squeeze(0).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OnTheFlySegmentation:\n",
    "    def __init__(self, model, frames: int):\n",
    "        self.model = model\n",
    "        self.n_frames = frames\n",
    "        self.frame_buffer: list[np.ndarray] = []\n",
    "\n",
    "    def set_n_frames(self, n: int):\n",
    "        self.n_frames = n\n",
    "    \n",
    "    def clear_buffer(self):\n",
    "        del self.frame_buffer\n",
    "        self.frame_buffer = []\n",
    "\n",
    "    def add_image(self, image: np.ndarray):\n",
    "        self.frame_buffer.append(torch.from_numpy(image))\n",
    "\n",
    "    def inference(self) -> np.ndarray:\n",
    "        if (len(self.frame_buffer) < self.n_frames):\n",
    "            raise ValueError(\"Number of frames in buffer smaller than requested amount.\")\n",
    "        \n",
    "        input_frames = torch.zeros((self.n_frames, *self.frame_buffer[0].shape))\n",
    "        for i in range(self.n_frames):\n",
    "            image = self.frame_buffer[i]\n",
    "            input_frames[i, :, :] = image\n",
    "        self.clear_buffer()\n",
    "\n",
    "        return inference(self.model, input_frames, apply_transforms=True).numpy()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "from PIL import Image, ImageTk\n",
    "def apply_color_map(data, cmap_name: str='viridis', vmin=None, vmax=None):\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "\n",
    "    norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "    rgba = cmap(norm(data))\n",
    "    rgb = rgba[:,:, :3]\n",
    "\n",
    "    return (255*rgb).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: 'saved_models\\default_model_v2.model'\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "\n",
    "model_class = PLSegmentationModel\n",
    "model_path = 'saved_models\\\\default_model_v2.model'\n",
    "\n",
    "model = model_class.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Synthetic dataset\n",
    "from models.psf import GuassionPSF\n",
    "from simulation.grain_PL_simulation import TrainingDataSimulationOptions\n",
    "from torch_utils.dataset import GeneratedPLOutlineDataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch_utils.transform import BackgroundRemovalNormalize, SkipFrames\n",
    "\n",
    "\n",
    "## 1 Pixel is 200 nm\n",
    "def get_training_data(length: int = 20) -> Dataset:\n",
    "    psf = GuassionPSF(2.5)\n",
    "\n",
    "    factor = 2\n",
    "    options = TrainingDataSimulationOptions(\n",
    "        grid_size=256 // factor,\n",
    "        min_grains=3000 // (2 * factor * factor),\n",
    "        max_grains=3200 // (2 * factor * factor),\n",
    "        min_noise=0.05 ,\n",
    "        max_noise=0.12,\n",
    "        sample_rate=10,\n",
    "        seconds=11, ## Decides how many frames each test samples has: total frames = sample_rate * seconds\n",
    "        min_blinker_transition=0.04,\n",
    "        max_blinker_transition=0.1,\n",
    "        min_base_counts=6000,\n",
    "        max_base_counts=12000,\n",
    "        min_hole_chance=0.01,\n",
    "        max_hole_chance=0.1,\n",
    "        min_boundary_dimish=0,    \n",
    "        max_boundary_dimish=1.0,\n",
    "        min_blinker_strength=0.005,\n",
    "        max_blinker_strength=0.08,\n",
    "        min_blinkers_average=50,\n",
    "        max_blinkers_average=80,\n",
    "        psf=psf,\n",
    "        label_scaling=2,\n",
    "    )\n",
    "\n",
    "    generated_dataset = GeneratedPLOutlineDataset(length=20, \n",
    "                                              sim_options=options,)\n",
    "\n",
    "    return generated_dataset\n",
    "\n",
    "dataset = get_training_data(20)\n",
    "# for _ in range(1000):\n",
    "#     for i in range(20):\n",
    "video, label = dataset.__getitem__(0)\n",
    "\n",
    "segmentation = OnTheFlySegmentation(model, 100)\n",
    "for i in range(100):\n",
    "    segmentation.add_image(\n",
    "        video[i, :, :].numpy()\n",
    "    )\n",
    "\n",
    "\n",
    "out = segmentation.inference()\n",
    "mapped = apply_color_map(out)\n",
    "\n",
    "im = Image.fromarray(mapped, mode='RGB')\n",
    "im.save('testing.png')\n",
    "\n",
    "mapped.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting acquisition\n",
      "Finished acquisition\n",
      "Starting inference\n",
      "Finished inference\n",
      "Max: 0.9863914251327515\n",
      "Output image size: (424, 424, 3)\n",
      "\n",
      "\n",
      "\n",
      "Starting acquisition\n",
      "Finished acquisition\n",
      "Starting inference\n",
      "Finished inference\n",
      "Max: 0.967772901058197\n",
      "Output image size: (424, 424, 3)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "from pycromanager import Acquisition\n",
    "from pycromanager import multi_d_acquisition_events\n",
    "import time\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Test On the Fly segmentation\")\n",
    "root.geometry(\"800x600\")\n",
    "\n",
    "# Create frame for button bar\n",
    "button_frame = tk.Frame(root, bg=\"#f0f0f0\")\n",
    "button_frame.pack(side=tk.TOP, fill=tk.X, padx=10, pady=10)\n",
    "\n",
    "current_image: Image.Image = None\n",
    "\n",
    "# Function to generate and display a random image\n",
    "def display_random_image():\n",
    "    # Generate a random image using NumPy\n",
    "    width, height = 400, 300\n",
    "    # Create random RGB data\n",
    "    img_data = np.random.randint(0, 255, (height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Convert NumPy array to PIL Image\n",
    "    img = Image.fromarray(img_data)\n",
    "    \n",
    "    # Convert to Tkinter-compatible image\n",
    "    photo = ImageTk.PhotoImage(img)\n",
    "    \n",
    "    # Update the label with the new image\n",
    "#    image_label.config(image=photo)\n",
    "    image_label.config(image=photo)\n",
    "    image_label.image = photo  # Keep a reference to prevent garbage collection\n",
    "\n",
    "\n",
    "# Button stubs\n",
    "def open_image():\n",
    "    # Stub function for opening an image\n",
    "    print(\"Open image button clicked\")\n",
    "\n",
    "def save_image():\n",
    "    global current_image\n",
    "\n",
    "    if not current_image:\n",
    "        return\n",
    "    \n",
    "    curr_time = int(time.time())\n",
    "    file_name = f'saved_images/{curr_time}_segmentation.png'\n",
    "    \n",
    "    current_image.save(file_name)\n",
    "\n",
    "def generate_random_image():\n",
    "    pass\n",
    "\n",
    "def generate_inference():\n",
    "    global current_image\n",
    "\n",
    "    n_frames = int(num_frames_entry.get())\n",
    "    segmentation = OnTheFlySegmentation(model, n_frames)\n",
    "\n",
    "    def add_image_func(im_data, metadata, *args):\n",
    "        segmentation.add_image(im_data)\n",
    "        return (im_data, metadata)\n",
    "\n",
    "    print('Starting acquisition')\n",
    "    with Acquisition(directory=None, name=None, image_process_fn=add_image_func, show_display=False) as acq:\n",
    "        events = multi_d_acquisition_events(num_time_points=n_frames)\n",
    "        acq.acquire(events)\n",
    "    print('Finished acquisition')\n",
    "\n",
    "    print('Starting inference')\n",
    "    result = segmentation.inference()\n",
    "    print('Finished inference')\n",
    "\n",
    "    mapped_imaged = apply_color_map(result)\n",
    "    print(f'Max: {np.max(result)}')\n",
    "\n",
    "    print(f'Output image size: {mapped_imaged.shape}')\n",
    "\n",
    "    pill_img = Image.fromarray(mapped_imaged, mode='RGB')\n",
    "    pill_img = pill_img.resize((800,800), Image.Resampling.NEAREST)\n",
    "    current_image = pill_img\n",
    "\n",
    "    photo = ImageTk.PhotoImage(pill_img)\n",
    "    image_label.config(image=photo)\n",
    "    image_label.image = photo\n",
    "    \n",
    "    print('\\n\\n')\n",
    "# Add buttons to the button bar\n",
    "open_button = tk.Button(button_frame, text=\"Open Image\", command=open_image)\n",
    "open_button.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "save_button = tk.Button(button_frame, text=\"Save Image\", command=save_image)\n",
    "save_button.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "generate_button = tk.Button(button_frame, text=\"Generate Random\", command=generate_random_image)\n",
    "generate_button.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "\n",
    "entry_label = tk.Label(button_frame, text=\"Number of frames: \")\n",
    "entry_label.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "num_frames_entry = tk.Entry(button_frame)\n",
    "num_frames_entry.pack(side=tk.LEFT, padx=2)\n",
    "num_frames_entry.insert(0, \"100\")\n",
    "\n",
    "acquire_button = tk.Button(button_frame, text=\"Acquire\", command=generate_inference)\n",
    "acquire_button.pack(side=tk.LEFT, padx=2)\n",
    "\n",
    "\n",
    "# Create frame for image display\n",
    "image_frame = tk.Frame(root, bg=\"#ffffff\")\n",
    "image_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "# Label to display image\n",
    "image_label = tk.Label(image_frame, bg=\"#ffffff\", text=\"Loading image...\")\n",
    "image_label.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# Schedule the initial image display after the main loop starts\n",
    "root.after(100, display_random_image)\n",
    "\n",
    "# Start the main loop\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
